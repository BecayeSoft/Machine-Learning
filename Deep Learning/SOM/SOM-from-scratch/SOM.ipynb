{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Organizing Map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a SOM, we follow these steps:\n",
    "\n",
    "1. Choose grid size\n",
    "2. Set random weight W of shape (1, n_cols)\n",
    "3. Choose an input vector from the data\n",
    "4. Calculte Euclidian distance between Xi and Wj,i  - the minimum is the BMU\n",
    "5. Update the weights: w(t+1) = w(t) + h(t) * lr(t) * (x - w(t))\n",
    "6. Repeat: Repeat steps 3-5 for a specified number of iterations, adjusting the learning rate and neighborhood function over time as needed.\n",
    "\n",
    "\n",
    "Where: \n",
    "* **Wj,i**: represent the Weights of the node j (W1,1 W1,2, ... W1,n_cols)\n",
    "* **BMU** (Best Matching Unit) is the node with the minimum euclidian to the input X.\n",
    "* **h**: the neighboring value. The closer a node is to the BMU, the higher h will be.\n",
    "* **lr**: is the learning rate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighboring Function**\n",
    "The neighboring fucntion calculates the dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood_function(winning_neuron, current_neuron, radius):\n",
    "    # Euclidan distance between BMU and another neuron\n",
    "    # D = sqrt(sum(Xi - Wi) ^ 2)\n",
    "    distance = np.linalg.norm(winning_neuron - current_neuron)\n",
    "\n",
    "    # we  update only neurons in the perimeter\n",
    "    # the smaller the distance between BMU and the neuron, the higher the returned value will be\n",
    "    # which means drastic updates.\n",
    "    if distance <= radius:\n",
    "        return np.exp(-distance**2 / (2*radius**2))\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MiniSom Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install MiniSom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information about customers who applied for a credit card. 0 means  rejected and 1 means approved.\n",
    "Our goal is to detect the outliers, i.e the approved customers who are potentially fraudulent.\n",
    "\n",
    "Since SOMs are unsupervised, we won't use the labels for training. Instead, they will compared to the SOM results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Credit_Card_Applications.csv')\n",
    "X = dataset.iloc[:, :-1].values \n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CustomerID  690 non-null    int64  \n",
      " 1   A1          690 non-null    int64  \n",
      " 2   A2          690 non-null    float64\n",
      " 3   A3          690 non-null    float64\n",
      " 4   A4          690 non-null    int64  \n",
      " 5   A5          690 non-null    int64  \n",
      " 6   A6          690 non-null    int64  \n",
      " 7   A7          690 non-null    float64\n",
      " 8   A8          690 non-null    int64  \n",
      " 9   A9          690 non-null    int64  \n",
      " 10  A10         690 non-null    int64  \n",
      " 11  A11         690 non-null    int64  \n",
      " 12  A12         690 non-null    int64  \n",
      " 13  A13         690 non-null    int64  \n",
      " 14  A14         690 non-null    int64  \n",
      " 15  Class       690 non-null    int64  \n",
      "dtypes: float64(3), int64(13)\n",
      "memory usage: 86.4 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15776156</td>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15739548</td>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15662854</td>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15687688</td>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15715750</td>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  \\\n",
       "0    15776156   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2   \n",
       "1    15739548   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2   \n",
       "2    15662854   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2   \n",
       "3    15687688   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2   \n",
       "4    15715750   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   \n",
       "\n",
       "   A13   A14  Class  \n",
       "0  100  1213      0  \n",
       "1  160     1      0  \n",
       "2  280     1      0  \n",
       "3    0     1      1  \n",
       "4   60   159      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.info())\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84268147, 1.        , 0.12526316, 0.40928571, 0.5       ,\n",
       "       0.23076923, 0.375     , 0.05561404, 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.5       , 0.05      , 0.01212   ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SOM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the doc, a general rule of thumb to set the size of the grid for a dimensionality reduction task is that it should contain 5 * sqrt(N) neurons where N is the number of samples.\n",
    "\n",
    "Our grid_size will be sqrt(5 * 690) = 58\n",
    "grid_size = grid_x * grid_y = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 5 * math.sqrt(len(X))\n",
    "grid_x = grid_y = math.ceil(math.sqrt(grid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(grid_x, grid_y) = (12, 12\n",
      "Number of features: 15\n"
     ]
    }
   ],
   "source": [
    "print(f'(grid_x, grid_y) = ({grid_x}, {grid_y}')\n",
    "print(f'Number of features: {X.shape[1]}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
