Hyperparameter tuning is the process of selecting the best hyperparameters for a machine learning model. Hyperparameters are settings or configuration choices for a machine learning algorithm that are not learned from data but must be set by the user before training. 

Examples of hyperparameters include the number or depth of trees in a random forest, the number of neighbors in a K-Nearest Neighbors, etc.

Hyperparameter tuning involves exploring different combinations of hyperparameters to find the optimal set that results in the best performance of the model on a given task or dataset. 

This section demonstrates at least one hyperparameter tuning technique: 
* Random Search


## References
* [WillKoehrsen/Machine-Learning-Projects/random_forest_explained](https://github.com/WillKoehrsen/Machine-Learning-Projects/tree/master/random_forest_explained)
*  [sklearn.model_selection.RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)
